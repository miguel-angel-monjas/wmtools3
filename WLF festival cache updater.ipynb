{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: latin-1 -*-\n",
    "\"\"\"This notebook builds the CSV-like file describing the WLF festivals in Spain\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "try :\n",
    "    import pywikibot as pb\n",
    "except :\n",
    "    import sys, inspect\n",
    "    current_folder = os.path.realpath(os.path.abspath(os.path.split(inspect.getfile(inspect.currentframe()))[0]))\n",
    "    folder_parts = current_folder.split(os.sep)\n",
    "    pywikibot_folder = os.sep.join(folder_parts[0:-1])\n",
    "\n",
    "    if current_folder not in sys.path:\n",
    "        sys.path.insert(0, current_folder)\n",
    "    if pywikibot_folder not in sys.path:\n",
    "        sys.path.insert(0, pywikibot_folder)\n",
    "\n",
    "    import pywikibot as pb\n",
    "\n",
    "import mwparserfromhell as mwh\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.wmtools import upload_to_commons, epoch_time, dms2dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_WLF2016_NAME = 'Commons:Wiki Loves Folk/{0}'.format(2016)\n",
    "FESTIVAL_DB_PAGE  = BASE_WLF2016_NAME + '/Festival DB'\n",
    "\n",
    "commons_site   = pb.Site(\"commons\", \"commons\")\n",
    "wikipedia_site = pb.Site(\"es\", \"wikipedia\")\n",
    "wikidata_site  = pb.Site(\"wikidata\", \"wikidata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(timestamp):\n",
    "    tdelta = timestamp - datetime.utcfromtimestamp(0)\n",
    "    return int(tdelta.total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annexes = [\n",
    "    ['Anexo:Fiestas de interés turístico de Andalucía', 'Andalusia'],\n",
    "    ['Anexo:Fiestas de interés turístico de Aragón', 'Aragon'],\n",
    "    ['Anexo:Fiestas de interés turístico de Asturias', 'Asturias'],\n",
    "    ['Anexo:Fiestas de interés turístico de Cantabria', 'Cantabria'],\n",
    "    ['Anexo:Fiestas de interés turístico de Castilla-La Mancha', 'Castile-La Mancha'],\n",
    "    ['Anexo:Fiestas de interés turístico de Castilla y León', 'Castile and León'],\n",
    "    ['Anexo:Fiestas de interés turístico de Cataluña', 'Catalonia'],\n",
    "    ['Anexo:Fiestas de interés turístico de la Comunidad de Madrid', 'Community of Madrid'],\n",
    "    ['Anexo:Fiestas de interés turístico de la Comunidad Valenciana', 'Valencian Community'],\n",
    "    ['Anexo:Fiestas de interés turístico de Extremadura', 'Extremadura'],\n",
    "    ['Anexo:Fiestas de interés turístico de las Islas Baleares', 'Balearic Islands'],\n",
    "    ['Anexo:Fiestas de interés turístico de las Islas Canarias', 'Canary Islands'],\n",
    "    ['Anexo:Fiestas de interés turístico de Galicia', 'Galicia'],\n",
    "    ['Anexo:Fiestas de interés turístico de La Rioja', 'La Rioja'],\n",
    "    ['Anexo:Fiestas de interés turístico de Navarra', 'Navarre'],\n",
    "    ['Anexo:Fiestas de interés turístico de la Región de Murcia', 'Region of Murcia'],\n",
    "    ['Anexo:Fiestas y tradiciones del País Vasco', 'Basque Country']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "festivals_df = pd.DataFrame(\n",
    "    columns=['name', 'aut_com', 'wikidata_id', 'wikidata_timestamp', 'category', 'cat_timestamp', 'image', 'latitude', 'longitude'])\n",
    "\n",
    "for annex in annexes:\n",
    "    pb.output(\"Processing annex \" + annex[0])\n",
    "    page = pb.Page(wikipedia_site, annex[0])\n",
    "    text = page.text\n",
    "    wikicode = mwh.parse(text)\n",
    "    templates = wikicode.filter_templates()\n",
    "\n",
    "    for template in templates:\n",
    "        if template.name.lower().strip() == \"fila wlf\":\n",
    "            df_row = dict()\n",
    "            df_row = {\n",
    "                'name': '',\n",
    "                'aut_com': annex[1],\n",
    "                'wikidata_id': '',\n",
    "                'wikidata_timestamp': '',\n",
    "                'category': '',\n",
    "                'cat_timestamp': '',\n",
    "                'image': '',\n",
    "                'latitude': 0,\n",
    "                'longitude': 0\n",
    "            }\n",
    "            lat = []\n",
    "            long = []\n",
    "            if template.get(\"coord\").value and len(template.get(\"coord\").value) > 2:\n",
    "                coord_content = template.get(\"coord\").value.strip()\n",
    "                wikicode = mwh.parse(coord_content)\n",
    "                coord_templates = wikicode.filter_templates()\n",
    "                coordinates = [i for i in coord_templates if (i.name.lower().strip() == 'coord') or (i.name.lower().strip() == 'coordenadas')]\n",
    "                for coordinate in coordinates:\n",
    "                    #print (coordinate.params)\n",
    "                    if len(coordinate.params) == 9:\n",
    "                        lat.append(dms2dd (coordinate.get(1).value.strip(),\n",
    "                                       coordinate.get(2).value.strip(),\n",
    "                                       coordinate.get(3).value.strip(),\n",
    "                                       direction=coordinate.get(4).value.strip()\n",
    "                                      ))\n",
    "                        long.append(dms2dd (coordinate.get(5).value.strip(),\n",
    "                                       coordinate.get(6).value.strip(),\n",
    "                                       coordinate.get(7).value.strip(),\n",
    "                                       direction=coordinate.get(8).value.strip()\n",
    "                                      ))\n",
    "                    elif len(coordinate.params) == 7:\n",
    "                        lat.append(dms2dd (coordinate.get(1).value.strip(),\n",
    "                                       coordinate.get(2).value.strip(),\n",
    "                                       0,\n",
    "                                       direction=coordinate.get(3).value.strip()\n",
    "                                      ))\n",
    "                        long.append(dms2dd (coordinate.get(4).value.strip(),\n",
    "                                       coordinate.get(5).value.strip(),\n",
    "                                       0,\n",
    "                                       direction=coordinate.get(6).value.strip()\n",
    "                                      ))\n",
    "                    elif len(coordinate.params) == 3:\n",
    "                        lat.append(float(coordinate.get(1).value.strip()))\n",
    "                        long.append(float(coordinate.get(2).value.strip()))\n",
    "                df_row['latitude'] = sum(lat)/len(lat)\n",
    "                df_row['longitude'] = sum(long)/len(long)\n",
    "                        \n",
    "            if template.get(\"nombre_enlace\").value and len(template.get(\"nombre_enlace\").value) > 2:\n",
    "                df_row[\"name\"] = template.get(\"nombre_enlace\").value.strip()\n",
    "\n",
    "            if template.get(\"wikidata\").value and len(template.get(\"wikidata\").value) > 2:\n",
    "                #print template.get(\"wikidata\").value.strip()\n",
    "                item_page = pb.Page(wikidata_site, title=template.get(\"wikidata\").value.strip())\n",
    "                try:\n",
    "                    df_row[\"wikidata_id\"] = template.get(\"wikidata\").value.strip()\n",
    "                    creation = item_page.oldest_revision\n",
    "                    df_row[\"wikidata_timestamp\"] = str(epoch_time(creation.timestamp))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            if template.get(\"imagen\").value and len(template.get(\"imagen\").value) > 2:\n",
    "                df_row[\"image\"] = template.get(\"imagen\").value.strip()\n",
    "\n",
    "            if template.get(\"categoría-Commons\").value and len(\n",
    "                    template.get(\"categoría-Commons\").value.strip()) > 3:\n",
    "                cat_page = pb.Page(commons_site, title=template.get(\"categoría-Commons\").value.strip(), ns=14)\n",
    "                try:\n",
    "                    creation = cat_page.oldest_revision\n",
    "                    df_row[\"category\"] = template.get(\"categoría-Commons\").value.strip()\n",
    "                    df_row[\"cat_timestamp\"] = str(epoch_time(creation.timestamp))\n",
    "                except:\n",
    "                    pass\n",
    "            festivals_df = festivals_df.append(df_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = StringIO()\n",
    "festivals_df.to_csv(buf, index=None, sep=';', encoding='utf-8', header=False)\n",
    "\n",
    "db_page = pb.Page(commons_site, FESTIVAL_DB_PAGE)\n",
    "db_page.text = u'<pre>\\n' + buf.getvalue() + u'</pre>'\n",
    "db_page.save(\"WLF Spain: festival database update\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
