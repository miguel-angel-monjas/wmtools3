{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: latin-1 -*-\n",
    "\"\"\"This notebook builds the CSV-like file describing the contributions to WLF in Spain in YEAR\"\"\"\n",
    "\n",
    "import os, sys, inspect\n",
    "\n",
    "try :\n",
    "    import pywikibot as pb\n",
    "    from pywikibot import pagegenerators, textlib\n",
    "    import mwparserfromhell as mwh\n",
    "\n",
    "except :\n",
    "    current_folder = os.path.realpath(os.path.abspath(os.path.split(inspect.getfile(inspect.currentframe()))[0]))\n",
    "    folder_parts = current_folder.split(os.sep)\n",
    "    pywikibot_folder = os.sep.join(folder_parts[0:-1])\n",
    "\n",
    "    if current_folder not in sys.path:\n",
    "        sys.path.insert(0, current_folder)\n",
    "    if pywikibot_folder not in sys.path:\n",
    "        sys.path.insert(0, pywikibot_folder)\n",
    "\n",
    "    import pywikibot as pb\n",
    "    from pywikibot import pagegenerators, textlib\n",
    "    import mwparserfromhell as mwh\n",
    "\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR                = 2017\n",
    "TAG                 = 'WLF'\n",
    "TAG_EXT             = 'Wiki Loves Folk'\n",
    "\n",
    "BASE_WLF_NAME       = \"Commons:{1}/{0}\".format(YEAR, TAG_EXT)\n",
    "LOG_PAGE            = BASE_WLF_NAME + u\"/Log\"\n",
    "\n",
    "WLF_CATEGORY          = \"Category:Images from {1} {0} in Spain\".format(YEAR, TAG_EXT)\n",
    "WLF_FINALIST_CATEGORY = \"Category:Images from {1} {0} in Spain (finalists)\".format(YEAR, TAG_EXT)\n",
    "\n",
    "commons_site = pb.Site(\"commons\", \"commons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2541"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_wlf = pb.Category(commons_site, WLF_CATEGORY)\n",
    "gen_wlf = pagegenerators.CategorizedPageGenerator(cat_wlf)\n",
    "\n",
    "images_wlf = [page.title(withNamespace=True) for page in gen_wlf if page.is_filepage()]\n",
    "len(images_wlf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving --> 50 image descriptions downloaded\n",
      "Retrieving --> 100 image descriptions downloaded\n",
      "Retrieving --> 150 image descriptions downloaded\n",
      "Retrieving --> 200 image descriptions downloaded\n",
      "Retrieving --> 250 image descriptions downloaded\n",
      "Retrieving --> 300 image descriptions downloaded\n",
      "Retrieving --> 350 image descriptions downloaded\n",
      "Retrieving --> 400 image descriptions downloaded\n",
      "Retrieving --> 450 image descriptions downloaded\n",
      "Retrieving --> 500 image descriptions downloaded\n",
      "Retrieving --> 550 image descriptions downloaded\n",
      "Retrieving --> 600 image descriptions downloaded\n",
      "Retrieving --> 650 image descriptions downloaded\n",
      "Retrieving --> 700 image descriptions downloaded\n",
      "Retrieving --> 750 image descriptions downloaded\n",
      "Retrieving --> 800 image descriptions downloaded\n",
      "Retrieving --> 850 image descriptions downloaded\n",
      "Retrieving --> 900 image descriptions downloaded\n",
      "WARNING: Http response status 503\n",
      "WARNING: Non-JSON response received from server commons:commons; the server may be down.\n",
      "WARNING: Waiting 5 seconds before retrying.\n",
      "Retrieving --> 950 image descriptions downloaded\n",
      "Retrieving --> 1000 image descriptions downloaded\n",
      "Retrieving --> 1050 image descriptions downloaded\n",
      "Retrieving --> 1100 image descriptions downloaded\n",
      "Retrieving --> 1150 image descriptions downloaded\n",
      "Retrieving --> 1200 image descriptions downloaded\n",
      "Retrieving --> 1250 image descriptions downloaded\n",
      "Retrieving --> 1300 image descriptions downloaded\n",
      "Retrieving --> 1350 image descriptions downloaded\n",
      "Retrieving --> 1400 image descriptions downloaded\n",
      "Retrieving --> 1450 image descriptions downloaded\n",
      "Retrieving --> 1500 image descriptions downloaded\n",
      "Retrieving --> 1550 image descriptions downloaded\n",
      "Retrieving --> 1600 image descriptions downloaded\n",
      "Retrieving --> 1650 image descriptions downloaded\n",
      "Retrieving --> 1700 image descriptions downloaded\n",
      "Retrieving --> 1750 image descriptions downloaded\n",
      "Retrieving --> 1800 image descriptions downloaded\n",
      "Retrieving --> 1850 image descriptions downloaded\n",
      "Retrieving --> 1900 image descriptions downloaded\n",
      "Retrieving --> 1950 image descriptions downloaded\n",
      "Retrieving --> 2000 image descriptions downloaded\n",
      "Retrieving --> 2050 image descriptions downloaded\n",
      "Retrieving --> 2100 image descriptions downloaded\n",
      "Retrieving --> 2150 image descriptions downloaded\n",
      "Retrieving --> 2200 image descriptions downloaded\n",
      "Retrieving --> 2250 image descriptions downloaded\n",
      "Retrieving --> 2300 image descriptions downloaded\n",
      "Retrieving --> 2350 image descriptions downloaded\n",
      "Retrieving --> 2400 image descriptions downloaded\n",
      "Retrieving --> 2450 image descriptions downloaded\n",
      "Retrieving --> 2500 image descriptions downloaded\n"
     ]
    }
   ],
   "source": [
    "images_df = pd.DataFrame(\n",
    "    columns=['image_title', 'wikidata_id', 'uploader', 'time_to_upload', 'timestamp', 'qi', 'finalist'])\n",
    "\n",
    "image_counter = 0\n",
    "for image in images_wlf:\n",
    "    page = pb.Page(commons_site, image)\n",
    "    text = page.text\n",
    "    wikicode = mwh.parse(text)\n",
    "    templates = wikicode.filter_templates()\n",
    "\n",
    "    if (image_counter != 0) and (image_counter % 50 == 0) :\n",
    "        pb.output ('Retrieving --> %d image descriptions downloaded' %(image_counter))\n",
    "    image_counter += 1\n",
    "    image_row = {'image_title': page.title(withNamespace=False), \n",
    "                 'wikidata_id': None, \n",
    "                 'uploader': None,\n",
    "                 'time_to_upload': None,\n",
    "                 'timestamp': None,\n",
    "                 'qi': None,\n",
    "                 'finalist': None}\n",
    "\n",
    "    WLF_identifier = ''\n",
    "    wlf_templates = [template for template in wikicode.filter_templates() \n",
    "                    if template.name.lower().strip() == \"wlf\"]\n",
    "    if len(wlf_templates) > 0:\n",
    "        WLF_identifier = wlf_templates[0].get(1).value.strip()\n",
    "    \n",
    "    image_row[\"wikidata_id\"] = WLF_identifier\n",
    "    \n",
    "    creation = page.oldest_revision\n",
    "    image_row[\"uploader\"] = creation[\"user\"]\n",
    "    \n",
    "    creation_time = creation.timestamp + timedelta(hours=2)\n",
    "    image_row[\"timestamp\"] = creation_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    try:\n",
    "        # Too old users do not have a user registration time\n",
    "        user_registration = pb.User(commons_site, title=creation[\"user\"]).registration()\n",
    "        image_row[\"time_to_upload\"] = (creation_time-user_registration).days\n",
    "    except :\n",
    "        user_registration = datetime(2006, 1, 1)\n",
    "        image_row[\"time_to_upload\"] = (creation_time-user_registration).days\n",
    "        \n",
    "    qi_templates = [template for template in wikicode.filter_templates() \n",
    "                   if template.name.lower().strip() == \"qualityimage\"]\n",
    "    \n",
    "    if len(qi_templates) > 0:\n",
    "        image_row[\"qi\"] = 'qi'\n",
    "        \n",
    "    cats = [cat.title(withNamespace=True) for cat in textlib.getCategoryLinks(text)]\n",
    "    if WLF_FINALIST_CATEGORY in cats:\n",
    "        image_row[\"finalist\"] = 'finalist'\n",
    "\n",
    "    images_df = images_df.append(image_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Page [[commons:Commons:Wiki Loves Folk/2017/Log]] saved\n"
     ]
    }
   ],
   "source": [
    "buf = StringIO()\n",
    "images_df.to_csv(buf, index=None, sep=';', encoding='utf-8', header=False)\n",
    "\n",
    "db_page = pb.Page(commons_site, LOG_PAGE)\n",
    "db_page.text = u'<pre>\\n' + buf.getvalue() + u'</pre>'\n",
    "db_page.save(\"{1} {0} in Spain: Contribution log update\".format(YEAR, TAG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
